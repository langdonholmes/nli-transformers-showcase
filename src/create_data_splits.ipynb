{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a5498b-6bb7-4435-b672-106171fac6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(font='Liberation Serif',\n",
    "              rc={'figure.figsize': (7.5,3.75),\n",
    "                  'font.size': 11,\n",
    "                 })\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "df = pd.read_parquet('../data/efcamdat_shatz_distro.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bdf2a-56ef-4f89-bc5c-fe0cf1cfe28d",
   "metadata": {},
   "source": [
    "# Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a8ba106-4990-474c-8950-47502fef99d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writing_id</th>\n",
       "      <th>learner_id</th>\n",
       "      <th>learner_id_categorical</th>\n",
       "      <th>nationality</th>\n",
       "      <th>l1</th>\n",
       "      <th>cefr</th>\n",
       "      <th>cefr_numeric</th>\n",
       "      <th>level</th>\n",
       "      <th>unit</th>\n",
       "      <th>topic_id_original</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_topic</th>\n",
       "      <th>topic_to_keep</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>grade</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>mtld</th>\n",
       "      <th>text</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>588741</th>\n",
       "      <td>618611</td>\n",
       "      <td>84027</td>\n",
       "      <td>84027.0</td>\n",
       "      <td>sa</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>A2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>thank</td>\n",
       "      <td>hair</td>\n",
       "      <td>41662</td>\n",
       "      <td>00:21:49.077</td>\n",
       "      <td>95</td>\n",
       "      <td>36</td>\n",
       "      <td>60.48</td>\n",
       "      <td>\\n\\t  Dear Ali, I had really great time with y...</td>\n",
       "      <td>Dear Ali, I had really great time with your fa...</td>\n",
       "      <td>alternative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295439</th>\n",
       "      <td>316249</td>\n",
       "      <td>99467</td>\n",
       "      <td>99467.0</td>\n",
       "      <td>sa</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>A2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>went</td>\n",
       "      <td>both topics</td>\n",
       "      <td>41011</td>\n",
       "      <td>18:32:27.440</td>\n",
       "      <td>97</td>\n",
       "      <td>68</td>\n",
       "      <td>80.92</td>\n",
       "      <td>\\n\\t  Hi, friend  I'm so sorry that I missed y...</td>\n",
       "      <td>Hi, friend I'm so sorry that I missed your wed...</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        writing_id  learner_id  learner_id_categorical nationality      l1  \\\n",
       "588741      618611       84027                 84027.0          sa  Arabic   \n",
       "295439      316249       99467                 99467.0          sa  Arabic   \n",
       "\n",
       "       cefr  cefr_numeric  level  unit  topic_id_original  ...  \\\n",
       "588741   A2             2      4     5                 29  ...   \n",
       "295439   A2             2      5     7                 39  ...   \n",
       "\n",
       "       secondary_topic  topic_to_keep   date          time grade wordcount  \\\n",
       "588741           thank           hair  41662  00:21:49.077    95        36   \n",
       "295439            went    both topics  41011  18:32:27.440    97        68   \n",
       "\n",
       "         mtld                                               text  \\\n",
       "588741  60.48  \\n\\t  Dear Ali, I had really great time with y...   \n",
       "295439  80.92  \\n\\t  Hi, friend  I'm so sorry that I missed y...   \n",
       "\n",
       "                                           text_corrected       sample  \n",
       "588741  Dear Ali, I had really great time with your fa...  alternative  \n",
       "295439  Hi, friend I'm so sorry that I missed your wed...         main  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = ['Portuguese', 'Mandarin', 'Spanish', 'Russian', 'German', 'Arabic']\n",
    "num_to_sample = df.l1.value_counts()['Arabic'] # by text\n",
    "\n",
    "# downsample other languages to number of observations for Arabic\n",
    "df_sampled = (df[df.l1.isin(languages)]\n",
    "              .groupby(['l1'])\n",
    "              .sample(n=num_to_sample, random_state=42)\n",
    "             )\n",
    "df_sampled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fce62c-b244-43d3-bb4d-6e5a6cb8a843",
   "metadata": {},
   "source": [
    "# Store unused data for Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47dd79d-bd67-421b-be64-e1cfab2de1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_df = df.loc[df.index.difference(df_sampled.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6ea497-eb0e-4728-a35b-00971d3e842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_df.to_parquet('../data/efcamdat_excluded_from_split.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06016c-339a-48c2-8d77-a32fc1d21b2b",
   "metadata": {},
   "source": [
    "# Split sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23816b37-c322-424e-bbe3-cae35b6069a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "\n",
    "def split_by_group(dataframe, group_var, test_size=.2, random_state=42, threeway=True):\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    split = splitter.split(dataframe, groups=dataframe[group_var].astype(int))\n",
    "    A_inds, B_inds = next(split)\n",
    "    train = dataframe.iloc[A_inds]\n",
    "    dev_test = dataframe.iloc[B_inds]\n",
    "    if not threeway:\n",
    "        return train, dev_test\n",
    "    else:\n",
    "        splitter = GroupShuffleSplit(n_splits=1, test_size=.5, random_state=random_state)\n",
    "        split = splitter.split(dev_test, groups=dev_test[group_var].astype(int))\n",
    "        A_inds, B_inds = next(split)\n",
    "        dev = dev_test.iloc[A_inds]\n",
    "        test = dev_test.iloc[B_inds]\n",
    "        return train, dev, test\n",
    "\n",
    "train, dev, test = split_by_group(df_sampled, 'learner_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5168a214-7f31-4b85-a8fa-133a39f41692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(train.learner_id.isin(test.learner_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96148647-7701-43ca-8167-3c9a67a80e63",
   "metadata": {},
   "source": [
    "# Dataset Dict Single Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad128c6-0007-4c23-a021-a1f9df0e1f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5fa48227de4dd09226ea4b74dd5c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/141 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2023c3c9134a1db0187bdd6e172090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5680db272bcb431f915e19271de92970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b7ae01eed940f88df148556b8cd76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d78fe4d4c64ac8a2c5d4f025727ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d9ab8a8d624da09deda47757e2ad49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "\n",
    "def make_dataset(dataframe):\n",
    "    dataframe = dataframe[['writing_id',\n",
    "                           'learner_id',\n",
    "                           'l1',\n",
    "                           'cefr',\n",
    "                           'grade',\n",
    "                           'text',\n",
    "                          ]]\n",
    "\n",
    "    return (Dataset\n",
    "            .from_pandas(dataframe.reset_index(drop=True))\n",
    "            .class_encode_column('l1')\n",
    "            .rename_column('l1', 'labels')\n",
    "           )\n",
    "\n",
    "datadict = DatasetDict(\n",
    "    {\n",
    "        'train': make_dataset(train),\n",
    "        'dev': make_dataset(dev),\n",
    "        'test': make_dataset(test),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e61e9118-6fe4-466d-b9d6-f0385064f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict.save_to_disk('../data/efcamdat_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91febfa5-ae97-413f-af3e-bdcf24daee9d",
   "metadata": {},
   "source": [
    "# Dataset Dict Concatenated Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b8823bb-7ece-4499-9d29-d78973f669c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', use_fast=True)\n",
    "\n",
    "tokenize = lambda text: len(tokenizer(text)['token_ids'])\n",
    "\n",
    "def concat_texts(dataframe):\n",
    "    dataframe['tok_count'] = dataframe['text'].apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69327584-39e6-4f6c-bb55-bda18fba3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = test.groupby(['cefr', 'learner_id'])['text'].agg(lambda x: '\\n'.join(x.str.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5b00124-356b-4c21-91b8-d50319fc1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda text: tokenizer(text, return_length=True)['length']\n",
    "tok_counts = grouped.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef16e234-c17e-4f55-98c2-4b4420e94508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cefr  learner_id\n",
       "A1    20              35\n",
       "      88              49\n",
       "      118             60\n",
       "      183             40\n",
       "      255             68\n",
       "                    ... \n",
       "C1    161478         192\n",
       "      161597         785\n",
       "      173136        1089\n",
       "      173210         865\n",
       "      173848         403\n",
       "Name: text, Length: 7014, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6481b8e3-50ff-4520-ba4b-8f6db545d7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588741    2\n",
       "295439    2\n",
       "47907     2\n",
       "29443     2\n",
       "95253     2\n",
       "         ..\n",
       "457324    2\n",
       "407898    2\n",
       "254091    2\n",
       "493453    2\n",
       "63941     2\n",
       "Name: text, Length: 140469, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].transform(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f061c0e-0f47-4d59-9301-d8b47363526d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567502     50\n",
       "106593     40\n",
       "638882     94\n",
       "236285     96\n",
       "691168    104\n",
       "         ... \n",
       "616134     57\n",
       "414827     44\n",
       "427060     43\n",
       "683520    116\n",
       "266538     73\n",
       "Name: text, Length: 17711, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].str.split().str.len()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
